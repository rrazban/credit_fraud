{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wPhHRPDiMwq"
      },
      "source": [
        "#1) Download the  data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYgFU6DDbcFs",
        "outputId": "c1628bb9-ecc4-4e37-b28d-6c5d86764464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/fraud-detection\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TtTWjoXwbhWq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('{0}/fraudTrain.csv'.format(path))\n",
        "test = pd.read_csv('{0}/fraudTest.csv'.format(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsALZ1LHdIxS"
      },
      "source": [
        "#2a) Transform the data\n",
        "\n",
        "1. Obtain the local time of day\n",
        "\n",
        "2. Transform date of birth to age\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v24Q1I7VT2EY"
      },
      "outputs": [],
      "source": [
        "#1) local transaction time\n",
        "\n",
        "state_timezone_map = {\n",
        "    'AL': 'America/Chicago',\n",
        "    'AK': 'America/Anchorage',\n",
        "    'AZ': 'America/Phoenix',       # No DST\n",
        "    'AR': 'America/Chicago',\n",
        "    'CA': 'America/Los_Angeles',\n",
        "    'CO': 'America/Denver',\n",
        "    'CT': 'America/New_York',\n",
        "    'DE': 'America/New_York',\n",
        "    'FL': 'America/New_York',      # Most of Florida\n",
        "    'GA': 'America/New_York',\n",
        "    'HI': 'Pacific/Honolulu',      # No DST\n",
        "    'ID': 'America/Boise',         # Split between MT and PT\n",
        "    'IL': 'America/Chicago',\n",
        "    'IN': 'America/Indiana/Indianapolis',\n",
        "    'IA': 'America/Chicago',\n",
        "    'KS': 'America/Chicago',\n",
        "    'KY': 'America/New_York',\n",
        "    'LA': 'America/Chicago',\n",
        "    'ME': 'America/New_York',\n",
        "    'MD': 'America/New_York',\n",
        "    'MA': 'America/New_York',\n",
        "    'MI': 'America/Detroit',\n",
        "    'MN': 'America/Chicago',\n",
        "    'MS': 'America/Chicago',\n",
        "    'MO': 'America/Chicago',\n",
        "    'MT': 'America/Denver',\n",
        "    'NE': 'America/Chicago',\n",
        "    'NV': 'America/Los_Angeles',\n",
        "    'NH': 'America/New_York',\n",
        "    'NJ': 'America/New_York',\n",
        "    'NM': 'America/Denver',\n",
        "    'NY': 'America/New_York',\n",
        "    'NC': 'America/New_York',\n",
        "    'ND': 'America/Chicago',\n",
        "    'OH': 'America/New_York',\n",
        "    'OK': 'America/Chicago',\n",
        "    'OR': 'America/Los_Angeles',\n",
        "    'PA': 'America/New_York',\n",
        "    'RI': 'America/New_York',\n",
        "    'SC': 'America/New_York',\n",
        "    'SD': 'America/Chicago',\n",
        "    'TN': 'America/Chicago',\n",
        "    'TX': 'America/Chicago',\n",
        "    'UT': 'America/Denver',\n",
        "    'VT': 'America/New_York',\n",
        "    'VA': 'America/New_York',\n",
        "    'WA': 'America/Los_Angeles',\n",
        "    'WV': 'America/New_York',\n",
        "    'WI': 'America/Chicago',\n",
        "    'WY': 'America/Denver'\n",
        "}\n",
        "\n",
        "def local_time(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    df['timezone'] = df['state'].map(state_timezone_map)\n",
        "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "    df['trans_date_trans_time'] = df['trans_date_trans_time'].dt.tz_localize('UTC')\n",
        "\n",
        "    local_dt = df.apply(\n",
        "        lambda row: row['trans_date_trans_time'].tz_convert(row['timezone']) if pd.notnull(row['timezone']) else pd.NaT,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    time_in_seconds = local_dt.apply(\n",
        "        lambda dt: dt.hour * 3600 + dt.minute * 60 + dt.second if pd.notnull(dt) else None\n",
        "    )\n",
        "\n",
        "    seconds_in_day = 24 * 60 * 60\n",
        "    seconds_norm = time_in_seconds / seconds_in_day\n",
        "\n",
        "    #acount for circularity of time of day\n",
        "    ##i.e. 12:59pm is close to 1pm\n",
        "    df['time_sin'] = np.sin(2 * np.pi * seconds_norm)\n",
        "    df['time_cos'] = np.cos(2 * np.pi * seconds_norm)\n",
        "\n",
        "    return df[['time_sin', 'time_cos']]\n",
        "\n",
        "\n",
        "train[['time_sin', 'time_cos']] = local_time(train)\n",
        "test[['time_sin', 'time_cos']] = local_time(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XCf3oGWfbOp4"
      },
      "outputs": [],
      "source": [
        "#2) Transform date of birth to age in years\n",
        "\n",
        "def get_age(df):\n",
        "\n",
        "    today = pd.Timestamp('2020-01-01')\n",
        "    #could have reference 'today' be transaction time but doesn't matter much because transactions are all within two years\n",
        "\n",
        "    df['dob'] = pd.to_datetime(df['dob'])\n",
        "    df['age'] = df['dob'].apply(lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)))\n",
        "\n",
        "    return df['age']\n",
        "\n",
        "train['age'] = get_age(train)\n",
        "test['age'] = get_age(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqB63zQFE-g2"
      },
      "source": [
        "#2b) Transform the data\n",
        "\n",
        "###Drop categorical and numerical columns not helpful to fraud prediction. Properly encode categorical columns for XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XZ8Z0zbAFLjt"
      },
      "outputs": [],
      "source": [
        "#columns to be removed\n",
        "no_need = ['cc_num', 'Unnamed: 0','street', 'city',  'dob','job','first',\n",
        "           'last','trans_num','trans_date_trans_time', 'lat', 'long', 'merch_lat',\n",
        "           'merch_long', 'unix_time','merchant','state']\n",
        "\n",
        "\n",
        "sparse_train = train.drop(columns = no_need)\n",
        "sparse_train['gender'] = sparse_train['gender'].astype('category')  #XGBoost can handle categorical variable\n",
        "sparse_train['category'] = sparse_train['category'].astype('category')\n",
        "\n",
        "sparse_test = test.drop(columns = no_need)\n",
        "sparse_test['gender'] = sparse_test['gender'].astype('category')\n",
        "sparse_test['category'] = sparse_test['category'].astype('category')\n",
        "\n",
        "#setup features (X) and the classification (y)\n",
        "y_train, X_train  = sparse_train['is_fraud'], sparse_train.drop(columns='is_fraud')\n",
        "y_test, X_test = sparse_test['is_fraud'], sparse_test.drop(columns='is_fraud')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvvRw4uP0wS8"
      },
      "source": [
        "#3) Explore the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See `fraud_detection.ipynb` for this section."
      ],
      "metadata": {
        "id": "r1Wfb731K9ng"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvBmDf9Z01oj"
      },
      "source": [
        "#4) Alright, time for some modeling!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train XGB on transformed data.\n",
        "#Reweight model to make fraud cases equal to non-fraud\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#find reweight\n",
        "counts = y_train.value_counts()\n",
        "scale_pos_weight = counts.get(0,0)/counts.get(1,0)  #use this to upweight fraud cases\n",
        "\n",
        "\n",
        "# Train XGBoost classifier\n",
        "clf_xgb = XGBClassifier(enable_categorical=True, device='cuda',tree_method='hist', eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
        "clf_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_xgb = clf_xgb.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2XHrA8rjRC3",
        "outputId": "f90b31ea-029e-44a0-db5f-021ffe1f98a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:32:07] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    553574\n",
            "           1       0.28      0.93      0.43      2145\n",
            "\n",
            "    accuracy                           0.99    555719\n",
            "   macro avg       0.64      0.96      0.71    555719\n",
            "weighted avg       1.00      0.99      0.99    555719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Try optimizing XGBoost parameters.\n",
        "\n",
        "\n",
        "1.   Random search\n",
        "2.   Grid search\n",
        "3.   Bayes optimization\n",
        "\n"
      ],
      "metadata": {
        "id": "-Iz45Y19wul-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A) Focus on recall"
      ],
      "metadata": {
        "id": "SLntYJs-2RJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3SKTzVtjovoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94443988-70e2-4190-ba8c-5709d298b021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Best params: {'subsample': 0.6, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 5, 'colsample_bytree': 0.8}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99    553574\n",
            "           1       0.14      0.97      0.24      2145\n",
            "\n",
            "    accuracy                           0.98    555719\n",
            "   macro avg       0.57      0.97      0.62    555719\n",
            "weighted avg       1.00      0.98      0.99    555719\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.3],\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'gamma': [0, 1, 5]\n",
        "}\n",
        "\n",
        "#this randomly samples\n",
        "search = RandomizedSearchCV(\n",
        "    clf_xgb, param_grid, n_iter=20, scoring='recall', cv=3, verbose=2, n_jobs=-1\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best params:\", search.best_params_)\n",
        "\n",
        "y_pred = search.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#parameter space is smaller because too many options\n",
        "#included parameters are default XGBoost and RandomizedSearchCV findings\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6],\n",
        "    'learning_rate': [0.05, 0.3],\n",
        "    'n_estimators': [100, 300],\n",
        "    'subsample': [0.6, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'min_child_weight': [1],\n",
        "    'gamma': [0, 5]\n",
        "}\n",
        "\n",
        "# This performs exhaustive search over the parameter grid\n",
        "search = GridSearchCV(\n",
        "    clf_xgb, param_grid, scoring='recall', cv=3, verbose=2, n_jobs=-1\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best params:\", search.best_params_)\n",
        "\n",
        "# Predict on test set using the best found model\n",
        "y_pred = search.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g3qfUoex-4L",
        "outputId": "4093584d-1a04-4d60-fd4d-a7bfa217f28a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
            "Best params: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 0.6}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99    553574\n",
            "           1       0.14      0.97      0.24      2145\n",
            "\n",
            "    accuracy                           0.98    555719\n",
            "   macro avg       0.57      0.97      0.62    555719\n",
            "weighted avg       1.00      0.98      0.99    555719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIU8-c5M0ZNF",
        "outputId": "f58e46b0-9875-47f2-d335-42d049758173"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.5.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "opt = BayesSearchCV(\n",
        "    clf_xgb,\n",
        "    {\n",
        "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
        "        'max_depth': Integer(3, 10),\n",
        "        'subsample': Real(0.5, 1.0),\n",
        "        'n_estimators': Integer(100, 500, prior = 'log-uniform'),\n",
        "        'colsample_bytree': Real(0.5, 1.0),\n",
        "        'min_child_weight': Integer(1, 10, prior = 'log-uniform'),\n",
        "        'gamma': Integer(0, 5)\n",
        "    },\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring='recall',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", opt.best_params_)\n",
        "\n",
        "# Predict on test set using the best found model\n",
        "y_pred = opt.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QkiKnR5y4bR",
        "outputId": "3f45fbf0-227a-48a0-dde3-65cc0f146695"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: OrderedDict([('colsample_bytree', 0.641714667121138), ('gamma', 0), ('learning_rate', 0.12307633054170765), ('max_depth', 4), ('min_child_weight', 1), ('n_estimators', 100), ('subsample', 1.0)])\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99    553574\n",
            "           1       0.13      0.97      0.23      2145\n",
            "\n",
            "    accuracy                           0.97    555719\n",
            "   macro avg       0.56      0.97      0.61    555719\n",
            "weighted avg       1.00      0.97      0.98    555719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###B) Consider both precision and recall"
      ],
      "metadata": {
        "id": "fm9C_LXJ2aDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.3],\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'gamma': [0, 1, 5]\n",
        "}\n",
        "\n",
        "#this randomly samples\n",
        "#average_precision maximizes AUC of precision-recall curve\n",
        "search = RandomizedSearchCV(\n",
        "    clf_xgb, param_grid, n_iter=20, scoring='average_precision', cv=3, verbose=2, n_jobs=-1\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best params:\", search.best_params_)\n",
        "\n",
        "y_pred = search.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2LGzi162fbI",
        "outputId": "c91e3952-77fc-4f79-8283-1c6981fac01c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'subsample': 0.6, 'n_estimators': 500, 'min_child_weight': 10, 'max_depth': 8, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 0.8}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    553574\n",
            "           1       0.40      0.91      0.56      2145\n",
            "\n",
            "    accuracy                           0.99    555719\n",
            "   macro avg       0.70      0.95      0.78    555719\n",
            "weighted avg       1.00      0.99      1.00    555719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parameter space is smaller because too many options\n",
        "#included parameters are default XGBoost and RandomizedSearchCV findings\n",
        "param_grid = {\n",
        "    'max_depth': [6,8],\n",
        "    'learning_rate': [0.05, 0.3],\n",
        "    'n_estimators': [100, 500],\n",
        "    'subsample': [0.6, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'min_child_weight': [1, 10],\n",
        "    'gamma': [0]\n",
        "}\n",
        "\n",
        "# This performs exhaustive search over the parameter grid\n",
        "search = GridSearchCV(\n",
        "    clf_xgb, param_grid, scoring='average_precision', cv=3, verbose=2, n_jobs=-1\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best params:\", search.best_params_)\n",
        "\n",
        "# Predict on test set using the best found model\n",
        "y_pred = search.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbPBTFDSzBbL",
        "outputId": "b3a96d5a-a44b-414a-c8f7-accf75b37a00"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
            "Best params: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 500, 'subsample': 0.6}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    553574\n",
            "           1       0.42      0.90      0.58      2145\n",
            "\n",
            "    accuracy                           0.99    555719\n",
            "   macro avg       0.71      0.95      0.79    555719\n",
            "weighted avg       1.00      0.99      1.00    555719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "opt = BayesSearchCV(\n",
        "    clf_xgb,\n",
        "    {\n",
        "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
        "        'max_depth': Integer(3, 10),\n",
        "        'subsample': Real(0.5, 1.0),\n",
        "        'n_estimators': Integer(100, 500, prior = 'log-uniform'),\n",
        "        'colsample_bytree': Real(0.5, 1.0),\n",
        "        'min_child_weight': Integer(1, 10, prior = 'log-uniform'),\n",
        "        'gamma': Integer(0, 5)\n",
        "    },\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring='average_precision',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", opt.best_params_)\n",
        "\n",
        "# Predict on test set using the best found model\n",
        "y_pred = opt.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksrOA8CS25a2",
        "outputId": "febfdcf1-b820-4270-919c-e76cc704b0ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: OrderedDict([('colsample_bytree', 1.0), ('gamma', 0), ('learning_rate', 0.0889011255833442), ('max_depth', 10), ('min_child_weight', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    553574\n",
            "           1       0.28      0.93      0.44      2145\n",
            "\n",
            "    accuracy                           0.99    555719\n",
            "   macro avg       0.64      0.96      0.72    555719\n",
            "weighted avg       1.00      0.99      0.99    555719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summary of results\n",
        "We are able to increase recall from 0.93 to 0.97 with optimized parameters for XGBoost. When optimizing based on 'average_precision', we find that precision increases at the slight detriment of recall. The different optimization approaches yield highly similiar results except for optimizing based on 'average_precision' for BayesianSearch."
      ],
      "metadata": {
        "id": "rOyz69k53CbF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FqxufnICF30E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}